{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.tuner import HyperparameterTuner, ContinuousParameter, IntegerParameter\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = SKLearn(\n",
    "    entry_point=\"train.py\",\n",
    "    source_dir=\"./training\",\n",
    "    framework_version=\"0.23-1\",\n",
    "    instance_type=\"local\",\n",
    "    instance_count=1,\n",
    "    base_job_name=\"training_tests\",\n",
    "    role=\"arn:aws:iam::111111111111:role/service-role/AmazonSageMaker-ExecutionRole-20200101T000001\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 53303rdge8-algo-1-obdbm ... \n",
      "Creating 53303rdge8-algo-1-obdbm ... done\n",
      "Attaching to 53303rdge8-algo-1-obdbm\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m 2021-12-10 03:10:39,949 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m 2021-12-10 03:10:39,951 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m 2021-12-10 03:10:39,960 sagemaker_sklearn_container.training INFO     Invoking user training script.\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m 2021-12-10 03:10:40,989 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m /miniconda3/bin/python -m pip install -r requirements.txt\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m Collecting imbalanced-learn==0.7.*\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m   Downloading imbalanced_learn-0.7.0-py3-none-any.whl (167 kB)\n",
      "\u001b[K     |████████████████████████████████| 167 kB 252 kB/s eta 0:00:01\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m \u001b[?25hCollecting lightgbm\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m   Downloading lightgbm-3.3.1-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.0 MB 1.8 MB/s eta 0:00:01\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m \u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /miniconda3/lib/python3.7/site-packages (from imbalanced-learn==0.7.*->-r requirements.txt (line 1)) (1.19.2)\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m Requirement already satisfied: scikit-learn>=0.23 in /miniconda3/lib/python3.7/site-packages (from imbalanced-learn==0.7.*->-r requirements.txt (line 1)) (0.23.2)\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m Requirement already satisfied: joblib>=0.11 in /miniconda3/lib/python3.7/site-packages (from imbalanced-learn==0.7.*->-r requirements.txt (line 1)) (1.0.1)\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m Requirement already satisfied: scipy>=0.19.1 in /miniconda3/lib/python3.7/site-packages (from imbalanced-learn==0.7.*->-r requirements.txt (line 1)) (1.5.3)\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m Requirement already satisfied: wheel in /miniconda3/lib/python3.7/site-packages (from lightgbm->-r requirements.txt (line 2)) (0.37.0)\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m Requirement already satisfied: threadpoolctl>=2.0.0 in /miniconda3/lib/python3.7/site-packages (from scikit-learn>=0.23->imbalanced-learn==0.7.*->-r requirements.txt (line 1)) (2.2.0)\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m Installing collected packages: lightgbm, imbalanced-learn\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m Successfully installed imbalanced-learn-0.7.0 lightgbm-3.3.1\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m \u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m \u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m You should consider upgrading via the '/miniconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m 2021-12-10 03:10:46,231 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m 2021-12-10 03:10:46,251 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m 2021-12-10 03:10:46,271 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m 2021-12-10 03:10:46,279 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m \n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m Training Env:\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m \n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m {\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m         \"train\": \"/opt/ml/input/data/train\",\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m         \"dev\": \"/opt/ml/input/data/dev\",\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m         \"test\": \"/opt/ml/input/data/test\",\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m         \"feats\": \"/opt/ml/input/data/feats\",\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m         \"txtml\": \"/opt/ml/input/data/txtml\"\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m     },\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m     \"current_host\": \"algo-1-obdbm\",\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m     \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m     \"hosts\": [\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m         \"algo-1-obdbm\"\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m     ],\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m     \"hyperparameters\": {},\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m         \"train\": {\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m         },\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m         \"dev\": {\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m         },\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m         \"test\": {\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m         },\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m         \"feats\": {\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m         },\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m         \"txtml\": {\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m         }\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m     },\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m     \"job_name\": \"training_tests-2021-12-10-03-10-25-876\",\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m     \"master_hostname\": \"algo-1-obdbm\",\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-681301531115/training_tests-2021-12-10-03-10-25-876/source/sourcedir.tar.gz\",\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m     \"module_name\": \"train\",\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m     \"num_cpus\": 12,\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m         \"current_host\": \"algo-1-obdbm\",\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m         \"hosts\": [\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m             \"algo-1-obdbm\"\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m         ]\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m     },\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m     \"user_entry_point\": \"train.py\"\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m }\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m \n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m Environment variables:\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m \n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m SM_HOSTS=[\"algo-1-obdbm\"]\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m SM_HPS={}\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m SM_USER_ENTRY_POINT=train.py\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-obdbm\",\"hosts\":[\"algo-1-obdbm\"]}\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m SM_INPUT_DATA_CONFIG={\"dev\":{\"TrainingInputMode\":\"File\"},\"feats\":{\"TrainingInputMode\":\"File\"},\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"},\"txtml\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m SM_CHANNELS=[\"dev\",\"feats\",\"test\",\"train\",\"txtml\"]\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m SM_CURRENT_HOST=algo-1-obdbm\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m SM_MODULE_NAME=train\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m SM_NUM_CPUS=12\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-681301531115/training_tests-2021-12-10-03-10-25-876/source/sourcedir.tar.gz\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"dev\":\"/opt/ml/input/data/dev\",\"feats\":\"/opt/ml/input/data/feats\",\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\",\"txtml\":\"/opt/ml/input/data/txtml\"},\"current_host\":\"algo-1-obdbm\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1-obdbm\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"dev\":{\"TrainingInputMode\":\"File\"},\"feats\":{\"TrainingInputMode\":\"File\"},\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"},\"txtml\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"training_tests-2021-12-10-03-10-25-876\",\"log_level\":20,\"master_hostname\":\"algo-1-obdbm\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-681301531115/training_tests-2021-12-10-03-10-25-876/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":12,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-obdbm\",\"hosts\":[\"algo-1-obdbm\"]},\"user_entry_point\":\"train.py\"}\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m SM_USER_ARGS=[]\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m SM_CHANNEL_DEV=/opt/ml/input/data/dev\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m SM_CHANNEL_TEST=/opt/ml/input/data/test\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m SM_CHANNEL_FEATS=/opt/ml/input/data/feats\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m SM_CHANNEL_TXTML=/opt/ml/input/data/txtml\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m PYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m \n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m \n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m /miniconda3/bin/python train.py\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m \n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m \n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m Received arguments: Namespace(colsample_bytree=1.0, dev_dir='/opt/ml/input/data/dev', learning_rate=0.1, min_child_samples=20, model_dir='/opt/ml/model', n_estimators=100, num_leaves=31, output_dir='/opt/ml/output', oversampling_rate=1.0, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0, subsample_freq=0, test_dir='/opt/ml/input/data/test', train_dir='/opt/ml/input/data/train')\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m Loading data...\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m Training and predicting...\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m Computing metrics...\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m Train metrics: {'recall_0_train': 0.8621315789473685, 'recall_1_train': 0.9075, 'precision_0_train': 0.9943847508043465, 'precision_1_train': 0.2573008222285228, 'f1_0_train': 0.9235474868209624, 'f1_1_train': 0.40092776673293573}\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m Dev metrics: {'recall_0_dev': 0.8597894736842105, 'recall_1_dev': 0.672, 'precision_0_dev': 0.9803168506961114, 'precision_1_dev': 0.2014388489208633, 'f1_0_dev': 0.9161058770749215, 'f1_1_dev': 0.3099630996309963}\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m Test metrics: {'recall_0_test': 0.8461052631578947, 'recall_1_test': 0.656, 'precision_0_test': 0.9790499390986601, 'precision_1_test': 0.18324022346368715, 'f1_0_test': 0.9077357425183512, 'f1_1_test': 0.28646288209606985}\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m Saving metrics...\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m Training the model on the whole dataset...\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m Saving the model...\n",
      "\u001b[36m53303rdge8-algo-1-obdbm |\u001b[0m 2021-12-10 03:10:51,267 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36m53303rdge8-algo-1-obdbm exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "base_uri = \"s3://sagemaker-us-east-1-681301531115/processing_tests-2021-12-07-02-39-45-682/output/\"\n",
    "estimator.fit(\n",
    "    inputs={\n",
    "        \"train\": base_uri + \"train_data/train.csv\",\n",
    "        \"dev\": base_uri + \"dev_data/dev.csv\",\n",
    "        \"test\": base_uri + \"test_data/test.csv\",\n",
    "        \"feats\": base_uri + \"features_info/features_info.json\",\n",
    "        \"txtml\": base_uri + \"text_model/text_model.joblib\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(\n",
    "    estimator=estimator,\n",
    "    objective_metric_name='f1_1_dev',\n",
    "    hyperparameter_ranges={\n",
    "        \"num_leaves\": IntegerParameter(1, 30, \"Linear\"),\n",
    "        \"learning_rate\": ContinuousParameter(0.0001, 0.5, \"Logarithmic\"),\n",
    "        \"n_estimators\": IntegerParameter(50, 5000, \"Logarithmic\"),\n",
    "        \"min_child_samples\": IntegerParameter(1, 5000, \"Logarithmic\"),\n",
    "        \"colsample_bytree\": ContinuousParameter(0.2, 1.0, \"Linear\"),\n",
    "        \"subsample\": ContinuousParameter(0.2, 1.0, \"Linear\"),\n",
    "        \"subsample_freq\": IntegerParameter(1, 10, \"Linear\"),\n",
    "        \"reg_alpha\": ContinuousParameter(0.0, 1.0, \"Logarithmic\"),\n",
    "        \"reg_lambda\": ContinuousParameter(0.0, 1.0, \"Logarithmic\"),\n",
    "    },\n",
    "    metric_definitions=[{'Name': 'f1_1_dev', 'Regex': 'f1_1_dev: (\\d\\.\\d+)'}],\n",
    "    max_jobs=50,\n",
    "    max_parallel_jobs=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_uri = \"s3://sagemaker-us-east-1-681301531115/processing_tests-2021-12-06-02-27-49-133/output/\"\n",
    "tuner.fit(\n",
    "    inputs={\n",
    "        \"train\": base_uri + \"train_data/train.csv\",\n",
    "        \"dev\": base_uri + \"dev_data/dev.csv\",\n",
    "        \"test\": base_uri + \"test_data/test.csv\",\n",
    "        \"feats\": base_uri + \"features_info/features_info.json\",\n",
    "        \"txtml\": base_uri + \"text_model/text_model.pkl\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to svt0lb071h-algo-1-25gzt\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m 2021-12-10 03:11:06,683 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m 2021-12-10 03:11:06,685 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m 2021-12-10 03:11:06,686 INFO - sagemaker-containers - nginx config: \n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m worker_processes auto;\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m daemon off;\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m pid /tmp/nginx.pid;\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m error_log  /dev/stderr;\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m \n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m worker_rlimit_nofile 4096;\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m \n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m events {\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m   worker_connections 2048;\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m }\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m \n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m http {\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m   include /etc/nginx/mime.types;\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m   default_type application/octet-stream;\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m   access_log /dev/stdout combined;\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m \n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m   upstream gunicorn {\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m     server unix:/tmp/gunicorn.sock;\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m   }\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m \n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m   server {\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m     listen 8080 deferred;\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m     client_max_body_size 0;\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m \n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m     keepalive_timeout 3;\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m \n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m     location ~ ^/(ping|invocations|execution-parameters) {\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m       proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m       proxy_set_header Host $http_host;\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m       proxy_redirect off;\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m       proxy_read_timeout 60s;\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m       proxy_pass http://gunicorn;\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m     }\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m \n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m     location / {\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m       return 404 \"{}\";\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m     }\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m \n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m   }\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m }\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m \n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m \n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m 2021-12-10 03:11:07,705 INFO - sagemaker-containers - Module train does not provide a setup.py. \n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m Generating setup.py\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m 2021-12-10 03:11:07,705 INFO - sagemaker-containers - Generating setup.cfg\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m 2021-12-10 03:11:07,705 INFO - sagemaker-containers - Generating MANIFEST.in\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m 2021-12-10 03:11:07,706 INFO - sagemaker-containers - Installing module with the following command:\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m /miniconda3/bin/python3 -m pip install . -r requirements.txt\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m \u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m    pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m Collecting imbalanced-learn==0.7.*\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m   Downloading imbalanced_learn-0.7.0-py3-none-any.whl (167 kB)\n",
      "\u001b[K     |████████████████████████████████| 167 kB 251 kB/s eta 0:00:01\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m \u001b[?25h2021/12/10 03:11:10 [crit] 25#25: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 172.18.0.1, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"localhost:8080\"\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m 172.18.0.1 - - [10/Dec/2021:03:11:10 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"python-urllib3/1.26.7\"\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m Collecting lightgbm\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m   Downloading lightgbm-3.3.1-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.0 MB 1.8 MB/s eta 0:00:01\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m \u001b[?25hRequirement already satisfied: scikit-learn>=0.23 in /miniconda3/lib/python3.7/site-packages (from imbalanced-learn==0.7.*->-r requirements.txt (line 1)) (0.23.2)\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m Requirement already satisfied: scipy>=0.19.1 in /miniconda3/lib/python3.7/site-packages (from imbalanced-learn==0.7.*->-r requirements.txt (line 1)) (1.5.3)\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m Requirement already satisfied: joblib>=0.11 in /miniconda3/lib/python3.7/site-packages (from imbalanced-learn==0.7.*->-r requirements.txt (line 1)) (1.0.1)\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m Requirement already satisfied: numpy>=1.13.3 in /miniconda3/lib/python3.7/site-packages (from imbalanced-learn==0.7.*->-r requirements.txt (line 1)) (1.19.2)\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m Requirement already satisfied: wheel in /miniconda3/lib/python3.7/site-packages (from lightgbm->-r requirements.txt (line 2)) (0.37.0)\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m Requirement already satisfied: threadpoolctl>=2.0.0 in /miniconda3/lib/python3.7/site-packages (from scikit-learn>=0.23->imbalanced-learn==0.7.*->-r requirements.txt (line 1)) (2.2.0)\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m Building wheels for collected packages: train\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m   Building wheel for train (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m \u001b[?25h  Created wheel for train: filename=train-1.0.0-py2.py3-none-any.whl size=7651 sha256=cec7452dd061e580c45541ded1780e5b9a2d3719a7bfdc2e6ef1c2f7c2ca6b60\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m   Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-lj_4dtm9/wheels/3e/0f/51/2f1df833dd0412c1bc2f5ee56baac195b5be563353d111dca6\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m Successfully built train\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m Installing collected packages: train, lightgbm, imbalanced-learn\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m Successfully installed imbalanced-learn-0.7.0 lightgbm-3.3.1 train-1.0.0\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m \u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m \u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m You should consider upgrading via the '/miniconda3/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m [2021-12-10 03:11:13 +0000] [61] [INFO] Starting gunicorn 20.0.4\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m [2021-12-10 03:11:13 +0000] [61] [INFO] Listening at: unix:/tmp/gunicorn.sock (61)\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m [2021-12-10 03:11:13 +0000] [61] [INFO] Using worker: gevent\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m [2021-12-10 03:11:13 +0000] [64] [INFO] Booting worker with pid: 64\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m [2021-12-10 03:11:13 +0000] [65] [INFO] Booting worker with pid: 65\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m [2021-12-10 03:11:13 +0000] [77] [INFO] Booting worker with pid: 77\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m [2021-12-10 03:11:13 +0000] [89] [INFO] Booting worker with pid: 89\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m [2021-12-10 03:11:13 +0000] [90] [INFO] Booting worker with pid: 90\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m [2021-12-10 03:11:13 +0000] [113] [INFO] Booting worker with pid: 113\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m [2021-12-10 03:11:14 +0000] [125] [INFO] Booting worker with pid: 125\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m [2021-12-10 03:11:14 +0000] [126] [INFO] Booting worker with pid: 126\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m [2021-12-10 03:11:14 +0000] [138] [INFO] Booting worker with pid: 138\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m [2021-12-10 03:11:14 +0000] [139] [INFO] Booting worker with pid: 139\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m [2021-12-10 03:11:14 +0000] [163] [INFO] Booting worker with pid: 163\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m [2021-12-10 03:11:14 +0000] [176] [INFO] Booting worker with pid: 176\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m 2021-12-10 03:11:15,560 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "!\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m 172.18.0.1 - - [10/Dec/2021:03:11:17 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"python-urllib3/1.26.7\"\n"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1, instance_type=\"local\", serializer=JSONSerializer(), deserializer=JSONDeserializer()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = {'id': 'd3d56eed-8a0c-4bd7-b163-39d17b4aa3ea',\n",
    " 'a': 4,\n",
    " 'b': 0.5879,\n",
    " 'c': 246212.65,\n",
    " 'd': 27.0,\n",
    " 'e': 1.627860465116279,\n",
    " 'f': 0.0,\n",
    " 'g': 'AR',\n",
    " 'h': 41,\n",
    " 'i': 'Cable Micro Hdmi A Hdmi Kolke 1.8mts C/ Doble Filtro Full Hd',\n",
    " 'j': 'cat_efed068',\n",
    " 'k': 0.8372673560737631,\n",
    " 'l': 1641.0,\n",
    " 'm': 38.0,\n",
    " 'n': 1,\n",
    " 'o': 'N',\n",
    " 'p': 'N',\n",
    " 'fecha': '2020-04-07 17:28:24',\n",
    " 'monto': 3.33}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m 2021-12-10 03:11:37,645 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36msvt0lb071h-algo-1-25gzt |\u001b[0m 172.18.0.1 - - [10/Dec/2021:03:11:39 +0000] \"POST /invocations HTTP/1.1\" 200 54 \"-\" \"python-urllib3/1.26.7\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fraude': 'sim', 'probabilidade': 0.8561303035221127}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "adf6705c6a90135cf9944b480ee041197a695f92a884e69181c17ec135bf3b1c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('sagemaker': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
